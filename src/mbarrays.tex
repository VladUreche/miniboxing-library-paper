\subsection{Arrays}
\label{sec:mbarrays}

% Arrays = Efficient bulk storage => The underlying container for many collections.
Arrays provide efficient memory usage and constant random access time, thanks to the elements being stored in a contiguous fashion. This is also optimal from a low level perspective as it cooperates well with processor caches, thanks to the spatial locality of the elements. For these reasons, arrays are commonly used as the underlying storage in high level collections, and are the container of choice for implementing performance-critical algorithms.

Since elements of an array are stored contiguously in memory, accessing an element requires knowing its size: assuming an integer is encoded on 4 bytes, a compiler will know that the $n^\text{th}$ element of an integer array stored at the address $a$ can be accessed by de-referencing the address $a + 4 \times n$. Or, in the case of a higher-level virtual machine, such as the JVM, to avoid tying the implementation to architecture details, each primitive array, such as |int[]| or |double[]| has its own bytecodes to access and update elements, which de-reference the correct address for the given architecture.

% Challenge : Abstraction <=> An Array[T] class that offers performances and versatility :
% no ClassTag or other ways that involve having to set restrictions on the type parameter or having to modify pre-existing code in order to adjust itself to the use of this new array abstraction :
%	- If one day we want to use Array[T : ClassTag] instead of SomeCollection[T] => need to modify a lot of code because ClassTags need to be propagated => Breaks the pre-existing code.
%	- If one day we want to use MbArray[T] instead of SomeCollection[T] => The pre-existing code will still work.

Unfortunately, while using primitive arrays offers optimal performance and memory usage, it also makes it difficult to abstract over the type of elements in the array: different types of elements have different sizes so the compiler needs to generate different instructions for array access depending on its element type. In practice, abstracting over the elements in arrays is essential for writing generic data structures, so language developers proposed different approaches to enable abstraction. One example is the template-based way, used in C++ and .NET, where generics are instantiated to primitive types, resolving their size before execution. On the other hand, languages where generics are compiled with erasure, such as Scala, lose the information necessary to resolve the object size at runtime and need to employ more complex mechanisms.

% Problem 1 : Accessing arrays of a generic type in scala is inefficient (big switch on the runtime type of the array)
A naive solution, commonly used in dynamic language interpreters which lack static information, is to convert all values stored in the array to object references, through boxing. This fixes the size of objects, since only references are stored in the array regardless of the primitive type. However, compact storage and locality are lost, since boxed primitives contain the additional object headers and can be allocated anywhere on the heap.

A much better approach transforms the Scala code that accesses or updates generic arrays. For example, the code:

\begin{lstlisting-nobreak}
 def first[T](a: Array[T]): T = a(0)
\end{lstlisting-nobreak}

Is transformed by the Scala compiler to:

\begin{lstlisting-nobreak}
 def first(a: Object): Any =
   a match {
     case x: Array[Object] => x(0) // size = reference
     case x: Array[Int]    => x(0)           // size = integer
     case x: Array[Double] => x(0) // size = double
     // and so on for all the primitive types of Scala
   }
\end{lstlisting-nobreak}


% Partial Solution (Optimization) : Assume that array of primitive types are using the optimized JVM arrays : Array[Int] is int[], Array[Double] is double[] etc.
With this transformation, which is similar to the accessor technique presented at the beginning of the section, accessing generic arrays becomes very involved: the program has to match over the possible primitive arrays, and only then it can access the element. This slows down program execution, but it also enforces a strong invariant: a Scala value of type |Array[Int]| is always represented as the JVM primitive integer array, |int[]|, and never as |Array[java.lang.Integer]|, which would require boxing the primitive values. This invariant guarantees that, outside the generic context, array access/update is efficient: an |Array[Int]| is always represented as the JVM primitive |int[]| array, which allows Scala to access and update elements without matching the array type. Therefore, from a language perspective, programmers only pay the extra overhead when using arrays with generics.

Another thing to notice is that the |Array[T]| type in the signature of |first| is transformed into |Object|: at the JVM level, primitive arrays such as |int[]|, |float[]| and |Object[]| have a single common parent class, which is |java.lang.Object|. This explains why there is a need to match the primitive array type: the |Array| class offered by Scala does not really exist, it's simply an abstraction over the primitive arrays offered by the JVM.

\subsubsection{Instantiating Arrays}

% But this optimization prevents instantiation of arrays in a generic context, because we cannot know at compile time which of int[], double[], Object[], etc we need to allocate.
Although the array representation invariant looks like a good deal so far, it introduces an unexpected problem: how to instantiate generic arrays? Exactly like accessing or updating an array, instantiating one must abide by the array invariant. Yet, with the erasure transformation, all traces of a generic type parameter |T| are removed, transforming the code:

\begin{lstlisting-nobreak}
 def newArray[T] = new Array[T](10)
\end{lstlisting-nobreak}

\noindent
into:

\begin{lstlisting-nobreak}
 def newArray() = /* error: T is erased */
\end{lstlisting-nobreak}

The |newArray| method should be able to produce any primitive array, based on the type argument of |newArray|:

\begin{lstlisting-nobreak}
 val a1: Array[Long] /* = long[] */ = newArray[Long]
 val a2: Array[Char] /* = char[] */ = newArray[Char]
\end{lstlisting-nobreak}

% Option 1 : Using a ClassTag for the type parameter can give us this info at runtime.
\textbf{Reified types.} To address this issue, Scala offers the |ClassTag| mechanism, which can be used to provide runtime information about a type parameter. This allows |newArray| to produce the correct primitive type:

\begin{lstlisting-nobreak}
 def newArray[T: `ClassTag`] = new Array[T](10)
\end{lstlisting-nobreak}

\noindent
is compiled to:

\begin{lstlisting-nobreak}
 def newArray(`tag: ClassTag`) = `tag`.newArray(10)
\end{lstlisting-nobreak}

% Problem 2 : ClassTags are expensive to :
%   - Synthesize (need to ask about this)
%   - Propagate (show an example of code)
%   - Store.
%     =>  people tend to avoid them.
Since the |ClassTag| object carries runtime information about the type |T|, it can instantiate the correct primitive array. Still, this approach is rarely used in practice because |ClassTag|s are expensive to synthesize, propagate and store.
To illustrate this, let us consider the following code:

\begin{lstlisting-nobreak}
 def foo[T] = bar[T]
 def bar[T] = baz[T]
 def baz[T] = new Vector[T](10)
\end{lstlisting-nobreak}

If we want to create a generic |Array| instead of the |Vector|:

\begin{lstlisting-nobreak}
 def baz[T] = `new Array[T](10)` // error: need ClassTag
\end{lstlisting-nobreak}

But this requires |baz| to have a |ClassTag| passed in:

\begin{lstlisting-nobreak}
 def baz[T: `ClassTag`] = `new Array[T](10)`
\end{lstlisting-nobreak}

Therefore, to call method |baz|, the caller needs to pass in a |ClassTag| object. When the call is made from non-generic code (e.g. |baz[Int]|), the |ClassTag| is synthesized by the compiler based on the type argument. This bears the cost of synthesis. And there is another cost, of propagation: the |baz| method is also a caller of |bar|, but since |bar|'s  type parameter |T| is erased, the compiler can't synthesize a |ClassTag| object. Instead, it must require its callers to provide it:

\begin{lstlisting-nobreak}
 def bar[T: `ClassTag`] = baz[T]
\end{lstlisting-nobreak}

Similarly, |foo| must require the |ClassTag| object to be passed from its callers, thus producing the following code:

\begin{lstlisting-nobreak}
 def foo[T: `ClassTag`] = bar[T]
 def bar[T: `ClassTag`] = baz[T]
 def baz[T: `ClassTag`] = `new Array[T](10)`
\end{lstlisting-nobreak}

This shows that generic code must be transitively modified to propagate |ClassTag| objects in order to allow instantiating arrays, explaining the cost of propagation. Finally, when dealing with objects, |ClassTag| objects have to be stored as fields in the object itself, adding to the program's memory footprint, explaining the storage cost.

% Option 2 : Always allocate Object[] (Array[AnyRef]) and use .asInstanceOf[Array[T]] on the object array to make the user believe.
% Problem 3 : This breaks the invariant Array[X] => x[] when X is a primitive. (show example of code that makes the JVM crash)
% 	=> The array must not escape, but this can be hard to guarantee.
\textbf{Breaking the invariant.} Another way to deal with this issue, without using |ClassTag|s, is to always instantiate |Array[AnyRef]| and force the compiler believe it is an |Array[T]|:

\begin{lstlisting-nobreak}
 def baz[T] = `new Array[AnyRef](10).asInstanceOf[Array[T]]`
\end{lstlisting-nobreak}

This approach forces boxing all elements, so it is known to affect performance. But, even worse, it breaks the array invariant: if the type parameter |T| is instantiated by |Int|, the returned array has type |Array[Int]| but its runtime type is |Object[]| instead of |int[]|.

Therefore this approach can only be used when the array is guaranteed to not escape to outside code. In practice, this approach is used to implement many of the generic collections in the Scala library.

% \vlad{mentioned this earlier}
% % Problem 4 : This is bad for performances, because primitives will need to be boxed in order to fit in the Object[] array.
%
% The other downside of this way of doing is that it will restrain performance when dealing with arrays of primitive types, as the primitive values will have to be boxed in order to fit in an |Array[AnyRef]|, therefore bringing it back to the problems stated earlier.



\textbf{Specialized arrays.} When using Scala specialization, the methods are duplicated and the type parameters are statically known. This allows the array invariant to be used to efficiently access arrays:

\begin{lstlisting-nobreak}
 def first[@specialized T](a: Array[T]): T = a(0)
\end{lstlisting-nobreak}

This will yield multiple variants of |first|, the default -- slow and unoptimized -- one, as well as nine fast specializations:

\begin{lstlisting-nobreak}
 def first(a: Object): Object =
   a match {
     ... // all ten cases
   }
 def first`_I`(a: int[]): int = a(0)
 def first`_J`(a: long[]): long = a(0)
 // and 7 other specialized variants...
\end{lstlisting-nobreak}

% Generic creation problem remains, due to the opportunistic nature of specialization:
%  * C[Int] may mean C_int, the specialized one, or C, the erased one, depending on the creation context
%  * but Array[Int] can only mean int[], not Object[]
% therefore ClassTags are still needed.

In this case, the generic (inefficient) version of the |first| method is still called in two cases:
\begin{itemize}
  \item from erased generic code;
  \item when the type parameter of |first| is instantiated by a reference type;
\end{itemize}

% Thanks to the array invariant, we know that the JVM type behind |Array[Int]| is |int[]|. Therefore, the bytecode generated for |first_int| will consist of optimized instructions that are specific to |int[]| instead of the long match. Having these two versions of |first|, the compiler will be able to choose which of them to call according to which type |T| is instanciated with. Subsequently, the default version of |first| will be picked whenever |T| is instantiated with anything but |Int|, and |first_int| will be picked whenever |T| is instantiated with |Int|. However it is worth noting that the optimized version will never get chosen if the call is made from a generic context without specialization. The reason is that type erasure would occur, thus making it impossible to reason about the instance of the type parameter in that context. For the exact same reason, specialization -- although it can help improving performances of array accesses -- does not provide any solution to the generic array instantiation problem:

Still, optimizing the specialized versions does not eliminate the need for |ClassTag| objects:

\begin{lstlisting-nobreak}
 def newArray[@specialized T]: Array[T] =
   new Array[T](10)
\end{lstlisting-nobreak}

Which is translated to:

\begin{lstlisting-nobreak}
 def newArray: Object = // error: no ClassTag
 def newArray_I: int[] = ...
 def newArray_J: long[] = ...
 // and 7 other specialized variants ...
\end{lstlisting-nobreak}

Inside the generic version of |newArray|, |T| is erased, so there is no way to instantiate the array anymore. And, as we have seen before, we cannot assume that the generic |newArray| will always be called with a reference type parameter:

\begin{lstlisting-nobreak}
 def foo[T] = newArray[T]
 val arr: Array[Int] = foo[Int]
\end{lstlisting-nobreak}

Therefore, the only correct solution is to require |newArray| to accept a |ClassTag| object, even before the specialized variants are created:

\begin{lstlisting-nobreak}
 def newArray[@specialized T: `ClassTag`]: Array[T] =
   new Array[T](10)
\end{lstlisting-nobreak}

Therefore, while specialization does reduce the overhead of acessing primitive arrays, it does not eliminate the need for |ClassTag| objects.

% . Consequently, the compiler will have no choice but the call the default erased variant of |newArray|. But since its type parameter is erased, it will not be able to instantiate the right array, thus bringing it back to the original problem. The code above does not compile, and |ClassTag|s are therefore still needed in order to instantiate arrays in a generic context. Furthermore, specialization of code is extremely expensive since it will produce additionnal bytecode in an exponential function of the number of type parameters that are specialized, thus making it close to impossible to ensure that all the generic code becomes specialized.

% Wrap up: what we've seen
%  - ClassTag approach       => advantage:    solves array instantiation problem
%                               disadvantage: has to carry ClassTag objects
%  - invariant approach      => advantage:    solves array instantiation problem
%                               disadvantage: array must not escape
%  - specialization approach => advantage:    optimize access
%                               disadvantage: opportunistic nature => does not solve the instantiation problem

\textbf{Recap.} We have seen three ways to implement generic arrays:

\vspace{-1em}
\begin{itemize}
  \item The |ClassTag| approach:
    \begin{compactitem}
      \item \textem{Advantage:} Solves the array instantiation problem;
      \item \textem{Disadvantage:} Has to carry |ClassTag| objects;
    \end{compactitem}
  \item Breaking the invariant approach:
    \begin{compactitem}
      \item \textem{Advantage:} Solves the array instantiation problem;
      \item \textem{Disadvantages:} Requires boxing primitives and arrays must not escape;
    \end{compactitem}
  \item The specialization approach:
    \begin{compactitem}
      \item \textem{Advantage:}	Optimizes array accesses;
      \item \textem{Disadvantage:} Does not solve the generic array instantiation problem.
    \end{compactitem}
\end{itemize}
\vspace{-1em}

% a natural question: can we combine the three approaches before to get something working?
\textbf{Miniboxed arrays.} Would it be possible to combine the three approaches seen so far to produce an alternative Array which does not have any of the disadvantages? In this subsection we present how |MbArray| achieves this, keeping the main advantages of each approach and dropping their disadvantages.

% enter MbArray:
%  - invariant approach      => advantage:    solves array instantiation problem
%                               disadvantage: array must not escape
%    solution: enclose the class into our own MbArray object, which can escape

%  - ClassTag approach       => advantage:    solves array instantiation problem
%                               disadvantage: has to carry ClassTag objects
%    solution: we can use the miniboxed information to specialize the internal array
%              in the MbArray object: in the miniboxed version for long => Array[Long],
%                                     in the miniboxed version for double => Array[Double]

%  - specialization approach => advantage:    optimize access
%                               disadvantage: opportunistic nature => does not solve the instantiation problem
%    solution: optimistically assume the MbArray object contains the specialized array. If so => fast path, if not => slow path


|MbArray| is a generic class that wraps a Scala |Array| but is also able to guarantee it does not escape, thus being similar to the ``Breaking the invariant'' approach. This allows programmers to instantiate |MbArray| objects without the need for a |ClassTag| object. It may seem this path will lead to boxing values in the array, but this is not the case: thanks to the tight integration with miniboxing, the |MbArray| class can reflectively decide what array to instantiate: either an array of objects or an array of long integers (the storage type). Therefore, the underlying array does not box the elements.

Finally, capitalizing on the tight integration with miniboxing, the array access procedures are transformed to optimistically access the underlying array directly, obtaining the miniboxed value right away. This is an opportunistic approach: there is a fast-path, when the storage type of the miniboxed class and the |MbArray| object coincide, or a slow path, when they don't. But, thanks to the guidance from the performance advisories, in the latter case only occurs with the programmer's consent, who knowingly allows the program to take the slow path.

With this approach, the following code:

\begin{lstlisting-nobreak}
 def first(a: MbArray[Int]): Int = a(0)
\end{lstlisting-nobreak}

Is translated to:

\begin{lstlisting-nobreak}
 def first(a: MbArray): Int =
   minibox2ing(mbArray_apply_J(a, 0))
\end{lstlisting-nobreak}

Where the |mbArray_apply| method contains the optimistic assumption that the |MbArray| is going to contain the miniboxed version of the |MbArray| class, containing an underlying array of long integers:

\begin{lstlisting-nobreak}
 def mbArray_apply_J[T](T_Type: Byte, a: MbArray[T], idx: Int): Long =
   a match {
     case x: MbArray_J => x.apply_J(idx)
     case x: MbArray_L => box2minibox(x.apply_L(idx))
   }
\end{lstlisting-nobreak}

In this case, going through the fast path does not require boxing but only a conversion from the miniboxed encoding to the unboxed integer. On the other hand, the slow path accesses an array of objects and transforms the boxed value into a miniboxed one, paying the cost of handling the boxed value.

% Coupled whith performance advisiories, we can direct the programmer away from the slow path => only going on the fast path :)

To conclude, the opportunistic nature of the |MbArray| coupled with performance advisories and miniboxing integration, allows it to have the following properties:
\begin{compactitem}
  \item Solves the array instantiation problem (no |ClassTag|s);
  \item Stores miniboxed values, which are more efficient than boxing;
  \item Accesses elements efficiently (if advisories are heeded).
\end{compactitem}

The next section presents a series of benchmarks which show how the miniboxing transformation integrates with the changes presented.

