\section{Introduction}
\label{sec:intro}

% Most optimizations => compromises => heuristics => opaque to programmers => hinders productivity

% Productiviy => high-level abstractions => redundant operations
Productivity in modern software development is achieved using high-level languages that allow programmers to focus on the requirements in the problem domain. The high-level programs are then transformed by compilers into low-level implementations that, when executed, produce the desired result. However, this translation is usually conservative and defensive: in checked languages, for example, accessing an array twice using the same index produces two array bounds checks, even though the second one is redundant.

% Productivity => optimizations (to close performance gap)
With programming languages targeting higher and higher abstraction levels, program optimizations are becoming crucial component to enabling productivity. Since high-level program translations routinely contain redundant operations, optimizations are used to reduce the performance gap between abstractions and their low-level, hand-coded equivalent implementations.

% Program optimizations are compromises.
While some optimizations can be guaranteed to produce better results (e.g. eliminating redundant bounds checks), others tend to be compromises. For example, many opportunistic transformations, such as shape analysis, split the program into two paths: a fast path, where the opportunistic shape assumptions are satisfied and the program is optimized and a slow path, which has to execute slower and more general operations. This makes opportunistic transformations a compromise: they can either speed up a section of the program by optimizing it or slow it down, by performing additional checks and triggering additional transformations.

% Ultimately, heuristics hinder productivity.
While opportunistic optimizations are a great tool to have in a compiler's toolbox, they are very difficult for the programmers to reason about: these transformations use opaque heuristics and can easily be invalidated by either new code additions or running the code for different types of data. Therefore, programmers treat these optimizations as black boxes and rely on benchmarks to reverse-engineer when and how the code is optimized. Ultimately, this affects productivity.

% Show how an opaque transformation => transparent
In this context, our paper explains how we offer programmers a window into the opportunistic   offering them compile-time warnings that explain what code prevents the optimization and how to  their code and how called miniboxing \cite{miniboxing}, which transforms generic classes and methods to allow them to handle unboxed primitive types.

% Sections
\topic{In the first part, we explain ...}

\topic{In the second part, we explain ...}

\topic{In the third part, we explain ...}

\topic{Contributions.}
% Contributions
%  - describe the mechanisms we used to offer transparency
%  - explain how we dealt with existing suboptimal API
%  - benchmark our changes and show how, combined, the sum of the parts is greater than each individual part.

% Conclusion
\topic{Conclusion.}



% Improving The Programmer Experience
%  - Performance Advisories
%  - Exposing internal state - MbReflection
% Bridging Existing Abstractions to Optimized Implementations
%  - Function => MbFunction
%  - Tuple    => accessors + constructors
% Exposing New Optimized Abstractions
%  - MbArray
% Benchmarks
%  - Performance Advisories => 5x improvement
%  - MbFunction
%  - MbArray => MbArray + MbFunction
%  - MbTuple => need benchmark
% Related Work